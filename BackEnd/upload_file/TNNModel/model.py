# -*- coding:utf-8 -*-from tensorflow import kerasimport pandas as pdimport pickleimport numpy as npfrom sklearn.metrics import r2_score# variablesmodel_dir = r'D:/github/DuLab/BackEnd/upload_file/TNNModel/Model/'# model_dir = '/Users/mawenbo/PycharmProjects/uploadApi/upload_file/TNNModel/Model/'# load model to predict'''    根据输入、模型名和预测目标进行预测，如果要获得F、T和S三个目标的预测值，需调用三次，每次传入的target name不同    @:parameter    data_x: pd.dataframe    model_name: str    target_name: str, 'F'/'T'/'S'    @:return    a list of the predictions'''def predict(data_x, model_name=None, target_name=None):    if model_name is None or target_name is None:        return None    norm_info = get_norm_info(target=target_name)    df_x = pd.DataFrame(data_x)    norm_x = normalization(target_name, norm_info, df_x=df_x)    pred_model = keras.models.load_model(model_dir + model_name + '.h5')    pred_y = pred_model.predict(norm_x)    ac_pred_y = denormalization(target_name, norm_info, array_y=pred_y)    return ac_pred_y.reshape(-1).tolist()'''    如果要获得F、T和S三个模型的评估信息，需调用三次，每次传入的target name不同    @:parameter    data_x: pd.dataframe    data_y: pd.series    model_name: str    target_name: str, 'F'/'T'/'S''''def evaluate_model(df_x, series_y, model_name=None, target_name=None):    if model_name is None or target_name is None:        return None    model = keras.models.load_model(model_dir + model_name + '.h5')    norm_info = get_norm_info(target=target_name)    norm_df_x = normalization(target_name, norm_info, df_x=df_x)    norm_series_y = normalization(target_name, norm_info, series_y=series_y)    norm_array_y = np.array(norm_series_y)    print(norm_series_y)    test_metrics = model.evaluate(x=norm_df_x, y=norm_array_y, verbose=0)    pred_y = model.predict(norm_df_x)    ac_pred_y = denormalization(target_name, norm_info, array_y=pred_y)    # for i, metric_name in enumerate(model.metrics_names):    #     print(metric_name + ": " + str(test_metrics[i]))    r2 = r2_score(norm_array_y, pred_y)    # print("r2 score: ", r2)    evaluate_result = {        "true_result": series_y.tolist(),        "pred_result": ac_pred_y.reshape(-1).tolist(),        "test_mse": test_metrics[-1],        "test_r2_score": r2    }    evaluate_data = []    print(evaluate_result["test_mse"])    print(evaluate_result["test_r2_score"])    # print(evaluate_result)    evaluate_data.append({"test_mse": evaluate_result["test_mse"], "test_r2_score": evaluate_result["test_r2_score"]})    return evaluate_result# 获取模型训练的相关结果# 如果要获得F、T和S三个模型的信息，需调用三次，每次传入的model_history_name不同def get_model_info(model_history_name):    with open(model_dir + model_history_name + '.pkl', 'rb') as his_f:        history = pickle.load(his_f)        training_loss = history['loss']        val_loss = history['val_loss']        test_mse = history['test_mean_squared_error']        test_r2_score = history['test_r2_score']        test_y = history['test_y']        pred_y = history['pred_y']        his_f.close()    model_info = {        "training_loss": training_loss,        "val_loss": val_loss,        "test_mse": test_mse,        "test_r2_score": test_r2_score,        "test_y": test_y,        "pred_y": pred_y    }    print(model_info)    return model_info'''@:parametertarget: str, 'F'/'T'/'S'**kwargs: df_x / series_y'''# 将实际值归一化def normalization(target, norm_info, **kwargs):    if 'df_x' in kwargs:        df_x = kwargs['df_x']        # dataframe zscore        x_cols = list(df_x.columns)        norm_df_x = pd.DataFrame(columns=x_cols)        for col in x_cols:            mean = norm_info[col][0]            std = norm_info[col][1]            norm_df_x[col] = (df_x[col] - mean) / std        return norm_df_x    elif 'series_y' in kwargs:        series_y = kwargs['series_y']        # series zscore        y_mean = norm_info['stable_' + target][0]        y_std = norm_info['stable_' + target][1]        norm_series_y = pd.Series((series_y - y_mean)/y_std)        return norm_series_y# 将预测出来的归一化的值变成实际值def denormalization(target, norm_info, array_y=None):    if array_y is None:        return None    # if type(series_y) is not 'Series':    #     series_y = pd.Series(series_y)    y_mean = norm_info['stable_' + target][0]    y_std = norm_info['stable_' + target][1]    form_y = array_y * y_std + y_mean    # normalization(target, norm_info, )    return form_y'''    @:return    norm_info: dict() feature_name: [mean, std]'''def get_norm_info(target):    norm_info_file = 'D:/github/DuLab/BackEnd/upload_file/TNNModel/Data/' + target + '_norm_info.txt'    norm_info = dict()    with open(norm_info_file, 'r',encoding='utf-8') as norm_f:        lines = norm_f.readlines()        for i, line in enumerate(lines):            if i == 0 or i == len(lines) - 2:                continue            infos = line.split()            if i == len(lines) - 1:                norm_info['stable_' + target] = [float(infos[1]), float(infos[-1])]            else:                norm_info[infos[0]] = [float(infos[1]), float(infos[-1])]        norm_f.close()    return norm_info# referencesif __name__ == '__main__':    # # predict    # test_file = '/Users/shuangliz/Desktop/分批测试数据/1/1_tnn.csv'    # data = pd.read_csv(test_file, sep=',', header=0)    # cols = data.columns.values    # feature_cols = cols[:-3]    # target_col = cols[-3]    # df_x = data[feature_cols]    # pred_y = predict(df_x, model_name='GABPNN_F', target_name='F')    # # series_y = data[target_col]    # # print(series_y)    # # print(pred_y)    # # model_info    # model_info = get_model_info('GABPNN_F_history')    # print(model_info)    # evaluate model by test data    test_file = r'D:\课件\大三上\实验杜\Data\upload_file\DataPreprocessAPI\DataPreprocessAPI\src\Data\tnn.csv'    # test_file = '/Users/mawenbo/PycharmProjects/uploadApi/upload_file/DataPreprocessAPI/DataPreprocessAPI/src/Data/tnn.csv'    data = pd.read_csv(test_file, sep=',', header=0)    cols = data.columns.values    feature_cols = cols[:-3]    target_col = cols[-1]  # F:-3, T:-2, S:-1    df_x = data[feature_cols]    series_y = data[target_col]    array_y = np.array(series_y)    evaluate_data = []    r2 = evaluate_model(df_x, array_y, model_name='GABPNN_F', target_name='F')["test_r2_score"]    r21 = evaluate_model(df_x, array_y, model_name='GABPNN_S', target_name='S')["test_r2_score"]    r23 = evaluate_model(df_x, array_y, model_name='GABPNN_T', target_name='T')["test_r2_score"]    print(r21)    # print(r21)    # print(r23)    # print(series_y)    # model_info1 = get_model_info('GABPNN_F_history')    # model_info2 = get_model_info('GABPNN_T_history')    # model_info3 = get_model_info('GABPNN_S_history')    # print(model_info1)    # print(model_info2)    # print(model_info3)    # print(model_info['test_mse'])    # evaluate_model(df_x, array_y, model_name='GABPNN_T', target_name='T')    # evaluate_model(df_x, array_y, model_name='GABPNN_S', target_name='S')    # print(evaluate_data)    # pass